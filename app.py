import streamlit as st
import cv2
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from torchvision.models import vgg16
from PIL import Image, ImageDraw, ImageFont

from facenet_pytorch import MTCNN
import time

# ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ
font_path = 'NanumGothicBold.ttf'

# ì–¼êµ´ ì¸ì‹ ëª¨ë¸ í´ëž˜ìŠ¤
class FaceRecognitionModel(nn.Module):
    def __init__(self):
        super(FaceRecognitionModel, self).__init__()
        self.model = vgg16(pretrained=False)
        self.model.classifier = nn.Sequential(
            *list(self.model.classifier.children())[:-1]
        )

    def forward(self, x):
        return self.model(x)

    def load_state_dict(self, state_dict):
        # ë¡œë“œí•  ë•Œ ì‚¬ìš©ë˜ëŠ” í‚¤ ì´ë¦„ì„ ìˆ˜ì •í•˜ì—¬ ì¼ì¹˜ì‹œí‚µë‹ˆë‹¤.
        new_state_dict = {}
        for key, value in state_dict.items():
            new_key = key.replace("features.", "model.features.")
            new_key = new_key.replace("classifier.", "model.classifier.")
            if "model.classifier.6" in new_key:
                continue
            new_state_dict[new_key] = value

        super(FaceRecognitionModel, self).load_state_dict(new_state_dict)


# ì–¼êµ´ ì¸ì‹ í•¨ìˆ˜
known_face_encodings = []  # ì´ˆê¸°í™”
known_face_names = []  # ì´ˆê¸°í™”


def recognize_face(model, face, known_face_encodings, known_face_names):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    face = Image.fromarray(face)
    face = transform(face).unsqueeze(0).to(DEVICE)

    with torch.no_grad():
        face_encoding = model(face).cpu().numpy().flatten()

    if len(known_face_encodings) == 0:
        return "New Face", face_encoding

    matches = np.linalg.norm(known_face_encodings - face_encoding, axis=1)

    if len(matches) > 0:
        min_distance_index = np.argmin(matches)
        if matches[min_distance_index] < 0.6:  # ìž„ê³„ê°’
            name = known_face_names[min_distance_index]
            return name, face_encoding

    return "New Face", face_encoding


# Streamlit ì•± ë©”ì¸ í•¨ìˆ˜
def main():
    st.title("ðŸ“¸ AI ì–¼êµ´ì¸ì‹ ì¶œê²°ê´€ë¦¬ ì‹œìŠ¤í…œ ðŸ“¸")

    # ì‚¬ì´ë“œë°”
    st.sidebar.subheader("ðŸ“ CVíŠ¸ëž™ ì¶œì„ë¶€")
    st.sidebar.checkbox('ê¹€ë¯¼ê¶Œ')
    st.sidebar.checkbox('ë„ìœ¤ì„œ')
    st.sidebar.checkbox('ë¥˜ì—¬ì§„')
    st.sidebar.checkbox('ë°•í˜„ì¤€')
    st.sidebar.checkbox('ì´í•˜ì˜')
    st.sidebar.checkbox('ìž„ì„±ì€')
    st.sidebar.checkbox('ìž¥ì„œì—°')

    st.sidebar.markdown("-------------------")
    st.sidebar.subheader("ðŸšª ì¶œíŠ€ ëª…ë‹¨")
    st.sidebar.write("1. ìž„ì„±ì€")
    st.sidebar.write("2. ë°•í˜„ì¤€")

    FRAME_WINDOW = st.image([])

    # MTCNN ë¡œë“œ
    mtcnn = MTCNN(keep_all=True, device=DEVICE)

    camera = cv2.VideoCapture(0)

    # ëª¨ë¸ ë¡œë“œ
    model_save_path = './model_pth/best_model.pth'
    model = FaceRecognitionModel().to(DEVICE)
    model.load_state_dict(torch.load(model_save_path, map_location=torch.device('cpu')))

    model.eval()

    # ì•Œë ¤ì§„ ì–¼êµ´ ì¸ì½”ë”© ë° ì´ë¦„ (ì´ ì˜ˆì œì—ì„œëŠ” ë¹„ì–´ ìžˆìŒ)
    known_face_encodings = []  # numpy ë°°ì—´ë¡œ ì €ìž¥ëœ ì¸ì½”ë”© ë¦¬ìŠ¤íŠ¸
    known_face_names = []  # ì¸ì½”ë”©ì— ëŒ€ì‘ë˜ëŠ” ì´ë¦„ ë¦¬ìŠ¤íŠ¸

    registering = False
    new_face_encoding = None

    form_key_suffix = 0  # ê³ ìœ í•œ í¼ í‚¤së¥¼ ë§Œë“¤ê¸° ìœ„í•œ ìˆ«ìž

    while True:
        ret, frame = camera.read()
        if not ret:
            st.write("ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        # ì¢Œìš° ë°˜ì „
        frame = cv2.flip(frame, 1)

        # ì–¼êµ´ ê²€ì¶œ
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        boxes, _ = mtcnn.detect(rgb_frame)

        # ì–¼êµ´ì— ì‚¬ê°í˜• ê·¸ë¦¬ê¸° ë° í…ìŠ¤íŠ¸ ì¶”ê°€
        if boxes is not None:
            for box in boxes:
                x, y, w, h = map(int, box)
                face = frame[y:h, x:w]
                name, face_encoding = recognize_face(model, face, known_face_encodings, known_face_names)
                cv2.rectangle(frame, (x, y), (w, h), (255, 0, 0), 2)
                

                # í•œê¸€ í°íŠ¸ ì„¤ì •
                font = ImageFont.truetype(font_path, 24)
                frame_pil = Image.fromarray(frame)
                draw = ImageDraw.Draw(frame_pil)
                draw.text((x, y - 10), name, font=font, fill=(255, 255, 255))
                frame = np.array(frame_pil)


                if name == "New Face" and not registering:
                    registering = True
                    new_face_encoding = face_encoding
                    st.write("ì²˜ìŒ ì˜¤ì…¨êµ°ìš”! ë“±ë¡ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
                    with st.form(f"register_form_{form_key_suffix}"):
                        student_id = st.text_input("í•™ë²ˆ")
                        student_name = st.text_input("ì´ë¦„")
                        submit = st.form_submit_button("ì œì¶œ")
                        if submit:
                            known_face_encodings.append(new_face_encoding)
                            known_face_names.append(student_name)
                            registering = False
                            success_message = st.success(f"{student_name} ë‹˜, ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                            time.sleep(3)  # 3ì´ˆê°„ ë©”ì‹œì§€ í‘œì‹œ
                            success_message.empty()  # ë©”ì‹œì§€ ì œê±°
                            form_key_suffix += 1

        # BGRì—ì„œ RGBë¡œ ë³€í™˜
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        FRAME_WINDOW.image(frame)

    camera.release()


if __name__ == '__main__':
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    main()
